{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krimits/Alloys/blob/main/Coding_Lecture_1_Diabetes_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkDo9d-NSfUW"
      },
      "source": [
        "# Προβλέποντας τον Διαβήτη με Μηχανική Μάθηση\n",
        "\n",
        "(Θυμίζουμε πως αυτό και τα ακόλουθα Colab Notebook είναι ``read-only``, οπότε αποθηκεύστε ένα αντίγραφο στο Drive σας, και μετακινήστε το σε όποιο φάκελο σας βολεύει: ``File``-->``Save a copy in Drive``).\n",
        "\n",
        "Ο Διαβήτης είναι παγκοσμίως από τις [κυριότερες αιτίες θανάτου](https://therapis-hospital.gr/sakcharodis-diavitis-mia-pagkosmia-ep/) (8η, στις ΗΠΑ). Ένα από τα βασικότερα προβλήματα έιναι η σωστή διάγνωση, όσο και η πρόβλεψη, και η πρόληψη.\n",
        "\n",
        "Για μας είναι μία αφορμή να χρησιμοποιήσουμε πραγματικά δεδομένα για να μάθουμε κάποιες βασικές έννοιες και τεχνηκές:\n",
        "\n",
        "* Πως κοιτάμε / επεξεργαζόμαστε / καθαρίζουμε τα δεδομένα\n",
        "* Ένα πρώτο μοντέλο: Ρηχά δέντρα απόφασης\n",
        "\n",
        "\n",
        "Κατεβάζουμε δεδομένα από το \"National Institute of Diabetes and Digestive and Kidney Diseases\" από εδώ:\n",
        "\n",
        "https://www.kaggle.com/datasets/mathchi/diabetes-data-set/data\n",
        "\n",
        "ή από το λινκ που σας δίνω πιο κάτω.\n",
        "\n",
        "<img src=\"https://www.aces.edu/wp-content/uploads/2022/03/FCS-2561-DEEP-Diabetes-Complications-Flyer081621L.jpg\" width=250px/>\n",
        "\n",
        "```\n",
        "Κωνσταντίνος Καραμανής: constantine@utexas.edu\n",
        "http://users.ece.utexas.edu/~cmcaram/\n",
        "The University of Texas at Austin\n",
        "Archimedes/Athena RC\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGypN0MG1Or6"
      },
      "source": [
        "## Οι Βασικοί Στόχοι του Colab Notebook\n",
        "\n",
        "Η βασική ιδέα της **επιτηρούμενης μάθησης** (supervised learning): Από παραδείγματα $X$ και $y$, θέλουμε να μάθουμε έναν **κανόνα** για να προβλέπουμε την αξία του $y$, όταν έχουμε μόνο τις αξίες του $X$. Δηλαδή, από τα χαρακτηριστικά, ή **features** του $X$ θέλουμε να μάθουμε πως να προβλέπουμε το $y$.\n",
        "\n",
        "Αυτό το Colab notebook θα μας βοηθήσει να καταλάβουμε: Πως είναι οργανωμένα τα δεδομένα, τι είναι αλγόριθμος και μοντέλο, πως εκπαιδεύουμε ένα μοντέλο ή τις παραμέτρους ενός μοντέλου, και πως χρησιμοποιούμε ένα εκπαιδευμένο μοντέλο για να κάνουμε προβλέψεις.\n",
        "\n",
        "Συγκεκριμένα, θα μας βοηθήσει:\n",
        "\n",
        "1. Να μάθουμε να μεταφορτώνουμε τα δεδομένα\n",
        "2. Να καταλάβουμε πως είναι οργανωμένα, και την ιδέα του $X, y$:\n",
        "  * Κάθε **σειρά** αντιπροσωπεύει έναν ασθενή. Οπότε η σειρά 5, για παράδειγμα, περιέχει τα χαρακτηριστικά (ή \"δεδομένα εισόδου\" ή **features**) που ξέρουμε για τον ασθενή νούμερο 5.\n",
        "  * Κάθε **στήλη** του $X$ αντιστοιχεί σε ένα από τα χαρακτηριστικά (**features**). Οπότε, όπως θα δούμε, η τρίτη στήλη του $X$ αντιστοιχεί στις μετρήσεις πίεσης. Η όγδοη στήλη στην ηλικία, κ.ο.κ.\n",
        "  * Το $y$ περιέχει ένα $0$ ή ένα $1$ για κάθε ασθενή -- αυτές είναι οι \"απαντήσεις\" που θέλουμε να μάθουμε να προβλέπουμε από το $X$.\n",
        "3. Να μάθουμε επίσης πως να οπτικοποιήσουμε τα δεδομένα, και εάν χρειάζεται, πως να τα \"καθαρίσουμε\".\n",
        "4. Πως θα βρούμε το καλύτερο δέντρο απόφασης -- δηλαδή, πως χρησιμοποιούμε τα δεδομένα για να **εκπαιδεύσουμε** ένα δέντρο απόφασης."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Βασικές Βιβλιοθήκες\n",
        "\n",
        "* sklearn -- περιέχει πολλούς αλγορίθμους μηχανικής μάθησης\n",
        "* Pandas -- χρήσιμη για να χειριζόμαστε δεδομένα\n",
        "* Numpy -- βασική βιβλιοθήκη για αριθμητική και υπολογισμούς\n",
        "* Matplotlib -- για απεικόνιση δεδομένων κα."
      ],
      "metadata": {
        "id": "OI6QlEwYtKMX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW60GEclVSBE"
      },
      "outputs": [],
      "source": [
        "# import important python libraries\n",
        "import pandas as pd # used for data manipulation and analysis.\n",
        "import numpy as np # used for numerical computations.\n",
        "import matplotlib.pyplot as plt # used for data visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uUX5YOAYheo"
      },
      "outputs": [],
      "source": [
        "# sets the seed for NumPy's random number generator to a specific value, in this case, 42\n",
        "# running code always gets same random numbers -- useful for debugging and verifying results.\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL9QfWjTS50l"
      },
      "source": [
        "## Μεταφορτώνουμε τα δεδομένα\n",
        "\n",
        "* Κατεβάστε το αρχείο στον υπολογιστή σας από [αυτό το λινκ](https://drive.google.com/file/d/1tq0aqY1Bdz3n2qc3IA0lf7o3QWgb6bXX/view?usp=sharing).\n",
        "* Αποθηκέυστε το στο Google Drive σας.\n",
        "\n",
        "* Πρέπει να δώσουμε στο Colab πρόσβαση στο Google Drive όπου είναι αποθηκευμένο το αρχείο -- το κάνουμε με τον παρακάτω κώδικα."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKuz1a7HSbY2"
      },
      "outputs": [],
      "source": [
        "# Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Διαβάζουμε τα δεδομένα\n",
        "\n",
        "Τώρα πρέπει να πούμε στην Colab να διαβάσει τα δεδομένα. Στο δικό μου Google Drive, τα έχω βάλει στο φάκελο\n",
        "```\n",
        "'/content/drive/MyDrive/Colab Notebooks/YouTube-Data-Sets/diabetes.csv'\n",
        "```\n",
        "\n",
        "Πρέπει να βρείτε το αρχείο στο δικό σας Google Drive.\n",
        "\n",
        "Η επόμενη εντολή διαβάζει τα δεδομένα από το Google Drive, και τα αποθηκεύει σε ένα DataFrame στο Pandas. Στο Pandas, ένα DataFrame είναι μια από τις βασικότερες και πιο δημοφιλείς δομές δεδομένων. Είναι ουσιαστικά ένας πίνακας δύο διαστάσεων (σαν φύλλο εργασίας του Excel), που χρησιμοποιείται για την αποθήκευση και επεξεργασία δεδομένων.\n",
        "\n",
        "Δεν θα μπούμε σε λεπτομέρειες του Pandas εδώ, αλλά θα δείτε αρκετές εντολές για να μπορείτε να το χρησιμοποιείτε."
      ],
      "metadata": {
        "id": "rkJ-w5ySuoAZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTB10ZAaTYr5"
      },
      "outputs": [],
      "source": [
        "# Replace 'path_to_your_file.csv' with the actual path to your CSV file\n",
        "#file_path = '/content/drive/MyDrive/Colab Notebooks/path_to_your_file.csv'\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/YouTube-Data-Sets/diabetes.csv'\n",
        "diabetes_data = pd.read_csv(file_path) #reads the CSV file located at file_path,\n",
        "                                       #loads the data into a Pandas DataFrame\n",
        "                                       #and assigns it to the variable diabetes_data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku6yK42YUUUc"
      },
      "source": [
        "### Πάντα κοιτάμε τα δεδομένα!\n",
        "\n",
        "Πρώτος βασικός κανόνας της μηχανικής μάθησης."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vKS6htVUAg5"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the dataframe\n",
        "pd.set_option('display.min_rows', 15)\n",
        "\n",
        "print(diabetes_data.shape) # displays the number of rows and columns of the array\n",
        "diabetes_data # prints the actual data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvi9nTMR8bLz"
      },
      "source": [
        "## Τι μάθαμε;\n",
        "\n",
        "Βλέπουμε πως έχουμε 768 σειρές, δηλαδή, δεδομένα από 768 ασθενείς. Επίσης, έχουμε 8 δεδομένα εισόδου, που είναι τα λεγόμενα **Features**:\n",
        "\n",
        "* Pregnancies\n",
        "* Glucose\n",
        "* Blood Pressure\n",
        "* Skin Thickness\n",
        "* Insulin\n",
        "* BMI\n",
        "* Diabetes Pedigree Function\n",
        "* Age\n",
        "\n",
        " και η τελευταία στήλη είναι αυτήν που θέλουμε να μάθουμε να προβλέπουμε: **Outcome** που για το παράδειγμά μας είναι εάν κάποιος είναι όντως διαβητικός."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qghqzzjlsbNh"
      },
      "source": [
        "## Τι Θέλουμε να Κάνουμε;\n",
        "\n",
        "Θέλουμε να χρησιμοποιήσουμε τα δεδομένα εισόδου (features) για να προβλέψουμε τα δεδομένα εξόδου (labels) που στην περίπτωσή μας είναι η τελευταία στήλη, \"Outcome\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Πόσοι έχουν διαβήτη;\n",
        "\n",
        "Πόσοι από τους 768 ασθενείς που περιέχουν τα δεδομένα μας είναι διαβητηκοί;  "
      ],
      "metadata": {
        "id": "IeuptQ4ow4uR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of rows that have a '1' as an outcome.\n",
        "diabetes_data['Outcome'].value_counts()"
      ],
      "metadata": {
        "id": "f_6OvtOaxZWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uokV0eW_VZV7"
      },
      "source": [
        "## Για Αρχή: Glucose & BMI\n",
        "\n",
        "Ας κοιτάξουμε μόνο δύο από τα δεδομένα εισόδου (features) και τα δεδομένα εξόδου (labels): (Glucose = ζάχαρο, BMI = δείκτης μάζας σώματος), και το \"Outcome\". Αυτό θα μας επιτρέψει να οπτικοποιήσουμε τα δεδομένα χρησιμοποιώντας δισδιάστατο διάγραμα διασποράς.\n",
        "\n",
        "Ο κώδικας\n",
        "\n",
        "```\n",
        "X = diabetes_data[['Glucose', 'BMI']].values\n",
        "```\n",
        "μετατρέπει τις δύο στήλες 'Glucose' και 'BMI' του Dataframe ``diabetes_data`` και τις αποθηκεύει σαν Numpy Array -- μία άλλη δομή δεδομένων που μας επιτρέπει να χρησιμοποιήσουμε την βιβλιοθήκη ``Numpy``.\n",
        "Αντίστοιχα, η εντολή\n",
        "```\n",
        "y = diabetes_data['Outcome'].values\n",
        "```\n",
        "κάνει το ίδιο με την στήλη 'Outcome'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_xwzsAYUWou"
      },
      "outputs": [],
      "source": [
        "X = diabetes_data[['Glucose', 'BMI']].values #extract Glucose and BMI columns from the DataFrame and converts them into a NumPy array\n",
        "y = diabetes_data['Outcome'].values #the same for the outcome column\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Διάγραμα Διασποράς\n",
        "\n",
        "Χρησιμοποιούμε την βιβλιοθήκη ``matplotlib`` για οπτικοποίηση δεδομένων. Δεν μπαίνουμε σε λεπτομέρειες, αλλά θα το χρησιμοποιήσουμε συχνά σε αυτά τα Notebook, οπότε στην πορεία θα μάθετε πολλές από τις βασικές χρήσεις και εντολές."
      ],
      "metadata": {
        "id": "a-Tk0_IMZTRT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKbN2pvOXiVx"
      },
      "outputs": [],
      "source": [
        "# Create a scatter plot (διάγραμμα διασποράς)\n",
        "plt.figure(figsize=(10, 6)) #This function creates a new figure, which is a container for all the plot elements and sets the width of the figure to 10 inches and the height to 6 inches\n",
        "for i in range(len(X)): #from 1 to 768 which is the length of the array\n",
        "    if y[i] == 0: #if outcome is 0\n",
        "        plt.scatter(X[i, 0], X[i, 1], color='blue', label='Outcome 0' if 'Outcome 0' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
        "    else: #if outcome is 1\n",
        "        plt.scatter(X[i, 0], X[i, 1], color='red', label='Outcome 1' if 'Outcome 1' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Glucose')\n",
        "plt.ylabel('BMI')\n",
        "plt.title('Scatter Plot of Glucose vs BMI')\n",
        "plt.legend()\n",
        "plt.show() # plot current figure to screen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YGLP4AaXtzF"
      },
      "source": [
        "### Περίεργες τιμές!\n",
        "\n",
        "Κανείς δεν έχει Glucose = 0, ούτε BMI = 0. Ας αφαιρέσουμε αυτά τα στοιχεία από τα δεδομένα μας."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwZ9n-GiXko5"
      },
      "outputs": [],
      "source": [
        "# Filter rows where either Glucose or BMI are zero\n",
        "filtered_data = diabetes_data[(diabetes_data['Glucose'] != 0) & (diabetes_data['BMI'] != 0)]\n",
        "\n",
        "# Now extract X and y\n",
        "X = filtered_data[['Glucose', 'BMI']].values\n",
        "y = filtered_data['Outcome'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ξαναβλέπουμε το διάγραμα διασποράς"
      ],
      "metadata": {
        "id": "mIp7tEutzEVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_P4B2ChYSkA"
      },
      "outputs": [],
      "source": [
        "# Create a scatter plot (διάγραμμα διασποράς)\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(len(X)):\n",
        "    if y[i] == 0:\n",
        "        plt.scatter(X[i, 0], X[i, 1], color='blue', label='Outcome 0' if 'Outcome 0' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
        "    else:\n",
        "        plt.scatter(X[i, 0], X[i, 1], color='red', label='Outcome 1' if 'Outcome 1' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Glucose')\n",
        "plt.ylabel('BMI')\n",
        "plt.title('Scatter Plot of Glucose vs BMI')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPSJ6_fJfFYC"
      },
      "source": [
        "# Έχουμε συζητήσει τα Δέντρα Απόφασης.\n",
        "\n",
        "Έχουμε δει και συζητήση τον βασικό ορισμό και την χρήση των Δέντρων Αποφάσεων στις διαλέξεις-με-διαφάνειες.\n",
        "\n",
        "Ας εφαρμόσουμε αυτές τις ιδέες σε αυτό το απλό παράδειγμα, χρησιμοποιώντας την βιβλιοθήκη ``sklearn``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ3haSOTZtsg"
      },
      "source": [
        "### Ένα ρηχό δέντρο απόφασης\n",
        "\n",
        "Αρχίζουμε με το πιο απλό δέντρο απόφασης -- που έχει βάθος ένα. Αυτό αντιστοιχεί στο διαχωρισμό των δεδομένων με βάση ένα όριο στην τιμή ενός \"feature\".\n",
        "\n",
        "Φυσικά, θα βρούμε με αυτοματοποιημένο/αλγοριθμικό τρόπο ποιό από τα δεδομένα, και πιο όριο, επιτυχαίνει την καλύτερη ακρίβεια στα δεδομένα.\n",
        "\n",
        "Ο σκοπός μας πάντα είναι να κατανοήσουμε μέσω απλων παραδειγμάτων ιδέες που μετά μπορούμε να εφαρμόσουμε σε πολύ πιο πολύπλοκα προβλήματα!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vlslb_KgYS7R"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "from sklearn import tree #import the tree module from the scikit-learn library\n",
        "from sklearn.tree import DecisionTreeClassifier # used to create a decision tree classifier\n",
        "from sklearn.metrics import accuracy_score # used to calculate the accuracy of a classification model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlNYV8OZHc3v"
      },
      "source": [
        "## Το βασικό πρότυπο εκπαίδευσης\n",
        "\n",
        "Ορίζουμε την οικογένεια μοντέλων.\n",
        "Μετά δίνουμε τα δεδομένα, και βρίσκουμε το καλύτερο μοντέλο από αυτήν την οικογένεια.\n",
        "\n",
        "```\n",
        "model = FamilyOfModels(some parameters)\n",
        "model.fit(X,y)\n",
        "```\n",
        "\n",
        "Στην δικιά μας περίπτωση:\n",
        "\n",
        "Εδώ ορίζουμε την οικογένεια: όλα τα δέντρα απόφασης με βάθος 1. Όπως έχουμε συζητήσει, αυτή η οικογένεια έχει 4 παραμέτρους.\n",
        "```\n",
        "koutsouro = DecisionTreeClassifier(max_depth=1)\n",
        "```\n",
        "Και εδώ είναι που εκπαιδεύουμε τον αλγόριθμο: βρίσκουμε το καλύτερο μοντέλο από την οικογένεια που ορίσαμε παραπάνω -- δηλαδή, βρίσκουμε αξίες για τις 4 παραμέτρους της οικογένειας ώστε το συγκεκριμένο μοντέλο (δέντρο) που προκύπτει να συμφωνεί σε μέγιστο βαθμό με τα δεδομένα μας: $(X,y)$.\n",
        "```\n",
        "koutsouro.fit(X, y)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awm5X6VVZ39M"
      },
      "outputs": [],
      "source": [
        "# Create a decision stump -- ρηχό δέντρο απόφασης = κούτσουρο!\n",
        "koutsouro = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# Fit the model on the training data\n",
        "koutsouro.fit(X, y) # The fit function is a method to train a machine learning model.\n",
        "                    # Note that .fit requires training data.\n",
        "                    # Also referred to as \"fitting the model.\"\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred = koutsouro.predict(X) # generate predictions from a trained machine learning model.\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y, y_pred) # compares the true labels with  predicted labels produced by the model and computes the accuracy\n",
        "                                     # number of correct predictions / total number of predictions\n",
        "print(\"Accuracy of the decision stump:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgAVeemm8A15"
      },
      "source": [
        "### Πόσο καλά τα πήγαμε;\n",
        "\n",
        "Χρησιμοποιούμε το\n",
        "\n",
        "```\n",
        "accuracy_score\n",
        "```\n",
        "αλλιώς θα μπορούσαμε μόνοι μας (σαν άσκηση) να γράψουμε function που το υπολογίζει.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "654zrCTU_ymr"
      },
      "source": [
        "## Πως μοιάζει το δέντρο μας;\n",
        "\n",
        "Ποιές είναι οι τιμές των 4 παραμέτρων που δίνουν την μεγαλύτερη ακρίβεια στα δεδομένα εκπαίδευσης;\n",
        "\n",
        "1. Ποιό feature επιλέγει για τον διαχωρισμό;\n",
        "2. Ποιό όριο βρίσκει για να γίνει ο διαχωρισμός;\n",
        "3. Τι τιμή (label) δίνει στα δεδομένα που ξεπερνάν το όριο;\n",
        "4. Και τι σε αυτά που δεν το ξεπερνάν;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45qmuxC7_14w"
      },
      "outputs": [],
      "source": [
        "tree.plot_tree(koutsouro, impurity=False, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9mipyR8aR1a"
      },
      "source": [
        "### Ας το δούμε και στο γράφημα"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25AKWpI8aOsd"
      },
      "outputs": [],
      "source": [
        "# Define the grid range based on your data\n",
        "x_min, x_max = X[:, 0].min() - 5, X[:, 0].max() + 5\n",
        "y_min, y_max = X[:, 1].min() - 5, X[:, 1].max() + 5\n",
        "\n",
        "# Create a meshgrid\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "# Predict the outcome on the meshgrid\n",
        "Z = koutsouro.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
        "\n",
        "# Plot the training points\n",
        "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolor='k')\n",
        "plt.xlabel('Glucose')\n",
        "plt.ylabel('BMI')\n",
        "plt.title('Decision Stump for Diabetes Prediction')\n",
        "plt.legend(handles=scatter.legend_elements()[0], labels=['Non-diabetic', 'Diabetic'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDBqEsd5axwR"
      },
      "source": [
        "### Βαθύτερα Δέντρα Απόφασης\n",
        "\n",
        "Θα τα ξανακάνουμε, αλλά με δέντρο απόφασης βάθους 2.\n",
        "Για την ακρίβεια, **θα το ξανακάνουμε μαζί**\n",
        "\n",
        "Έχουμε αφήσει κάποια κενά. Προσπαθήστε να τα συμπληρώσετε, χρησιμοποιώντας φυσικά αυτά που κάναμε παραπάνω."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Yi_zpjfawKW"
      },
      "outputs": [],
      "source": [
        "# Create a decision tree of depth 2\n",
        "depth_two_tree = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model on the training data\n",
        "depth_two_tree.fit(X,y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred2 = depth_two_tree.predict(X)\n",
        "\n",
        "\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y, y_pred2)\n",
        "print(\"Accuracy of the depth two decision tree:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ο διαχωρισμός του χώρου"
      ],
      "metadata": {
        "id": "sfdeK9hpgz-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3-F3JPLbCF1"
      },
      "outputs": [],
      "source": [
        "# Define the grid range based on your data\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "# Create a meshgrid\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "# Predict the outcome on the meshgrid\n",
        "Z2 = depth_two_tree.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z2 = Z2.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.contourf(xx, yy, Z2, alpha=0.8, cmap=plt.cm.coolwarm)\n",
        "\n",
        "# Plot the training points\n",
        "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolor='k')\n",
        "plt.xlabel('Glucose')\n",
        "plt.ylabel('BMI')\n",
        "plt.title('Depth two tree for Diabetes Prediction')\n",
        "plt.legend(handles=scatter.legend_elements()[0], labels=['Non-diabetic', 'Diabetic'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ibk1eBff7S5"
      },
      "source": [
        "# Διαχωρισμό με Logistic Regression και Gradient Boosting\n",
        "\n",
        "Το πρώτυπο που είδαμε παραπάνω είναι παρόμοιο με τον τρόπο που χρησιμοποιούμε (επιλέγουμε και εκπαιδεύουμε) άλλους αλγορίθμους της μηχανικής μάθησης.\n",
        "\n",
        "Δεν θα μπούμε σε λεπτομέρειες των συγκεκριμένων αλγορίθμων σε αυτήν την διάλεξη / notebook. Αλλά δίνουμε άλλα 2 παραδείγματα:\n",
        "\n",
        "  Α. Logistic Regression -- βρίσκει έναν καλό γραμμικό διαχωρισμό των δεδομένων\n",
        "\n",
        "  B. Gradient Boosting -- χρησιμοποιεί πολλά ρηχά δέντρα απόφασης για να βρεί έναν περίπλοκο κανόνα ταξινόμησης.\n",
        "\n",
        "**Τα βασικά που θέλουμε να δούμε και να καταλάβουμε:**\n",
        "\n",
        "* Παρόλο που οι δύο αλγόριθμοι (logistic regression & gradient boosting) είναι διαφορετικοί από τα δέντρα απόφασης, το πρότυπο χρήσης είναι παρόμοιο:\n",
        "  \n",
        "```\n",
        "model = FamilyOfModels(some parameters)\n",
        "model.fit(X.y)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit logistic regression model\n",
        "\n",
        "# import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# declare the family (Logistic Regression)\n",
        "LR_model = LogisticRegression()\n",
        "\n",
        "# fit the model to the data\n",
        "LR_model.fit(X, y)"
      ],
      "metadata": {
        "id": "T5SIWesm_ZZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Τι ακρίβεια πετυχαίνουμε;"
      ],
      "metadata": {
        "id": "_cSUGKgm_5wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute accuracy\n",
        "y_pred_lr = LR_model.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred_lr)\n",
        "print(\"Accuracy of Logistic Regression:\", accuracy)"
      ],
      "metadata": {
        "id": "9-tB-v1-_8fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Απεικονίζουμε τον διαχωρισμό του χώρου\n",
        "\n",
        "Ο κώδικάς είναι σχεδόν απαράλαχτος από αυτόν που χρησιμοποιήσαμε παραπάνω."
      ],
      "metadata": {
        "id": "1hFsKF7v_nrR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWzYxrxKbOzm"
      },
      "outputs": [],
      "source": [
        "# Define the grid range based on your data\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "# Create a meshgrid\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "# Predict the outcome on the meshgrid\n",
        "Z2 = LR_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z2 = Z2.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.contourf(xx, yy, Z2, alpha=0.8, cmap=plt.cm.coolwarm)\n",
        "\n",
        "# Plot the training points\n",
        "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolor='k')\n",
        "plt.xlabel('Glucose')\n",
        "plt.ylabel('BMI')\n",
        "plt.title('Logistic Regression for Diabetes Prediction')\n",
        "plt.legend(handles=scatter.legend_elements()[0], labels=['Non-diabetic', 'Diabetic'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting\n",
        "\n",
        "Χρησιμοποιεί πολλά ρηχά δέντρα απόφασης για να βρεί έναν περίπλοκο κανόνα ταξινόμησης."
      ],
      "metadata": {
        "id": "rbNbe5CACW1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# declare the family (Gradient Boosting Classifier)\n",
        "GB_model = XGBClassifier()\n",
        "\n",
        "# fit the model on the training data\n",
        "GB_model.fit(X, y)\n",
        "\n",
        "# compute accuracy\n",
        "y_pred_lr = GB_model.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred_lr)\n",
        "print(\"Accuracy of Gradient Boosting:\", accuracy)"
      ],
      "metadata": {
        "id": "6WnmU2McCV_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Εντυπωσιακή ακρίβεια!\n",
        "\n",
        "Θα το ξαναδούμε πιο προσεχτικά αυτό στην επόμενη διάλεξη, και θα δούμε πως πέρα από αυτήν την ακρίβεια πάνω στα δεδομένα εκπαίδευσης, υπάρχει κάποιο πρόβλημα. Μπορείτε να το σκεφτείτε και μόνοι σας, χρησιμοποιώντας τα εργαλεία που έχουμε δει πιο πάνω."
      ],
      "metadata": {
        "id": "BVjMQI9BKACS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV8ag-bWAbQp"
      },
      "source": [
        "# Για το Επόμενο Μάθημα: Υπερμοντελοποίηση\n",
        "\n",
        "Είδαμε παραπάνω πως το XGBoost πετυχαίνει πολύ υψηλή ακρίβεια πάνω στα δεδομένα με το οποία εκπαιδεύτηκε.\n",
        "\n",
        "Το ίδιο συμβαίνει εάν αντί για δέντρα απόφασης βάθους ένα ή δύο, εκπαιδεύσουμε\n",
        "**πιο βαθιά δέντρα απόφασης**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMHcruyQ_j_y"
      },
      "outputs": [],
      "source": [
        "# set depth\n",
        "\n",
        "d = 15 # depth of the tree\n",
        "\n",
        "# Create a decision tree\n",
        "deeptree = DecisionTreeClassifier(max_depth=d)\n",
        "\n",
        "# Fit the model on the training data\n",
        "deeptree.fit(X, y)\n",
        "# Make predictions\n",
        "y_pred = deeptree.predict(X)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy of the deep decision tree:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QONAIdRlbcRY"
      },
      "source": [
        "# Διαβήτης -- Μέρος ΙΙ -- **Άσκηση**\n",
        "\n",
        "Θα επαναλάβετε την λογική που ακολουθήσαμε στο πρώτο μισό του Colab Notebook, για να κάνετε τα εξής:\n",
        "\n",
        "1. Χρησιμοποιώντας άλλα \"features\" -- για παράδειγμα, \"Age\" & \"Blood Pressure\":\n",
        "  * Να ξεδιαλέξετε αυτά τα δύο χαρακτηριστικά (features), όπως κάναμε αρχικά για BMI και Glucose.\n",
        "  * Να χρησιμοποιήσετε το model.fit για να βρείτε το καλύτερο δέντρο βάθους 1 και 2, πάνω σε αυτά τα δύο features.\n",
        "  * Να απεικονίσετε τον διαχωρισμό του χώρου που προκύπτει.\n",
        "2. Να συγκρίνετε ποιό είναι καλύτερο (μέσω του accuracy) -- τα αποτελέσματα με αυτά τα δυο χαρακτηριστικά, η με τα πρώτα δύο που διαλέξαμε.\n",
        "3. Κατόπιν, να κοιτάξετε παραπάνω από 2 features -- τώρα δεν μπορούμε πλέον να τα απεικονίσουμε μιά που χρειαζόμαστε παραπάνω από τις 2 διαστάσεις της εικόνας, αλλά μπορούμε να χρησιμοποιήσουμε τους ίδιους αλγορίθμους -- δέντρα απόφασης βάθους 1, και βάθους 2, για να δούμε εάν τα πάμε καλύτερα χρησιμοποιώντας συγχρόνως όλα τα features."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Συμπληρώστε τα κενά και τα ΧΧΧΧΧ"
      ],
      "metadata": {
        "id": "Cs_AahkAikUO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEUBA9fA1KLG"
      },
      "outputs": [],
      "source": [
        "# θα ξεδιαλέξουμε τα χαρακτηριστικά 'Age' και 'Blood Pressure' -- χρησιμοποιούμε το filtered_data\n",
        "X = XXXXX\n",
        "# τα outcomes\n",
        "y = XXXXX\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(len(X)):\n",
        "    if y[i] == 0:\n",
        "        plt.scatter(X[i, 0], X[i, 1], color='blue', label='Outcome 0' if 'Outcome 0' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
        "    else:\n",
        "        plt.scatter(X[i, 0], X[i, 1], color='red', label='Outcome 1' if 'Outcome 1' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('XXXXX')\n",
        "plt.ylabel('XXXXX')\n",
        "plt.title('XXXXX')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glR7t_3VNBGC"
      },
      "source": [
        "### Έχουμε περίεργες τιμές;\n",
        "\n",
        "Εάν υπάρχουν περίεργες τιμές όπως και πρίν, τότε να τις αφαιρέσετε, έτσι δημιουργόντας ένα καινούργιο dataframe όπως κάναμε και αρχικά.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# αφαιρούμε τις σειρές (τους ασθενείς)\n",
        "# με τιμές που δεν βγάζουν νόημα\n",
        "# θα χρησιμοποιήσετε παρόμοιο κώδικα με αυτόν\n",
        "# που κάναμε μαζί.\n",
        "\n",
        "XXXXX\n",
        "\n",
        "# ξανα ορίζουμε το Χ και y\n",
        "X = XXXXX\n",
        "# τα outcomes\n",
        "y = XXXXX"
      ],
      "metadata": {
        "id": "avRZOwKISEOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5dVY58v1p3e"
      },
      "source": [
        "### Δέντρα απόφασης\n",
        "\n",
        "Πάλι μπορούμε να δούμε πόσο καλά τα πάει ένα ρηχό δέντρο απόφασης.\n",
        "\n",
        "* Accuracy;\n",
        "* Καλύτερο, χειρότερο, το ίδιο με πρίν;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# εκπαιδεύστε ένα ρηχώ δέντρο απόφασης πάνω στα δύο\n",
        "# δεδομένα (features) 'Age' και 'Blood Pressure'\n",
        "# θα χρησιμοποιήσετε παρόμοιο κώδικα με αυτόν\n",
        "# που κάναμε μαζί.\n",
        "\n"
      ],
      "metadata": {
        "id": "5GqBlBNPSi1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Πως μοιάζει ο διαχωρισμός του χώρου;"
      ],
      "metadata": {
        "id": "0Cm3Gk23602g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XXXXX # θυμίζουμε πως μπορείτε να αντιγράψετε τον κώδικα από παραπάνω"
      ],
      "metadata": {
        "id": "_KaBAfRA7CyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYmz475315yb"
      },
      "source": [
        "## Χρησιμοποιώντας Όλα τα Δεδομένα\n",
        "\n",
        "Μπορούμε τώρα να δοκιμάσουμε να χρησιμοποιήσουμε όλα τα δεδομένα. Παρόλο που δεν μπορούμε να τα δούμε τα δεδομένα στην οθόνη, για να βρούμε το καλύτερο δέντρο απόφασης (βάθους d) μπορούμε να ακολουθήσουμε ακριβώς την ίδια λογική, χρησιμοποιώντας τις ίδιες εντολές."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHUQhSpIgZoN"
      },
      "outputs": [],
      "source": [
        "# Τα δεδομένα\n",
        "X_full = morefiltered_data.values\n",
        "y = morefiltered_data['Outcome'].values\n",
        "\n",
        "\n",
        "# Create a decision tree\n",
        "model = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_full,y)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred2 = model.predict(X_full)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y, y_pred2)\n",
        "print(\"Accuracy of the decision tree:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUzmJIOa-YZm"
      },
      "source": [
        "## Puzzle\n",
        "\n",
        "**Ποιό (μοιραίο) λάθος κάναμε;\n",
        "Γιατί μας βγάζει 100% accuracy;**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6KS3YRBIiHt"
      },
      "source": [
        "### Απάντηση:\n",
        "\n",
        "Γιατί το $X_{\\rm full}$ περιέχει και την στήλη **Outcome**!\n",
        "Τέτοια λάθη είναι πολύ εύκολα να μην τα προσέξουμε. Πάντα πρέπει να χρησιμοποιούμε την κρίση μας όταν βλέπουμε κάποιο αποτέλεσμα: \"Γιατί είναι τόσο καλό; Βγάζει νόημα;\" ή και επίσης \"γιατί δεν δούλεψε όπως περίμενα;\"... Η τεχνητή νοημοσύνη είναι ακόμα... τεχνητή... δεν μας έχει αντικαταστήσει ακόμα!\n",
        "\n",
        "\n",
        "Μπορείτε να χρησιμοποιήσετε την εντολή\n",
        "```\n",
        "tree.plot_tree(model, impurity=False)\n",
        "```\n",
        "για να δείτε ποιό ήταν το δέντρο που πέτυχε 100% ακρίβεια -- θα δείτε πως έβγαλε αποφάσεις με βάση την τελευταία στήλη!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree.plot_tree(model, impurity=False)"
      ],
      "metadata": {
        "id": "sOA3wqZJ_2iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vlu8wHD9wWh"
      },
      "outputs": [],
      "source": [
        "# Πάμε Πάλι!\n",
        "X_full = morefiltered_data.loc[:, filtered_data.columns != 'Outcome'].values\n",
        "\n",
        "# Create a decision tree\n",
        "tree_d2 = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# Fit the model on the training data\n",
        "tree_d2.fit(X_full, y)\n",
        "# Make predictions\n",
        "y_pred2 = tree_d2.predict(X_full)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y, y_pred2)\n",
        "print(\"Accuracy of the decision stump:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw7OxclQAMc7"
      },
      "source": [
        "# Δεν μας βοήθησαν τελικά τα παραπάνω δεδομένα εισόδου\n",
        "\n",
        "Τα πήγαμε όσο καλά τα πήγαμε και χρησιμοποιώντας μόνο BMI & Glucose.\n",
        "\n",
        "Στο επόμενο μάθημα θα επιστρέψουμε σε αυτό το παράδειγμα, για να καταλάβουμε καλύτερα τι γίνεται, και τι άλλο θα μπορούσαμε να κάνουμε, και, το πιο σημαντικό, γιατί η υψηλή ακρίβεια που πετυχαίνει το XGBoost και τα βαθιά δέντρα απόφασης τελικά δεν προσφέρουν την μαγική λύση που ζητάμε."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fiTj88XbT_ps"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}